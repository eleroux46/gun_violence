{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petit test markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"cfe9b1c7-78be-4a5b-9de5-34fce4ff5f63\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"cfe9b1c7-78be-4a5b-9de5-34fce4ff5f63\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"cfe9b1c7-78be-4a5b-9de5-34fce4ff5f63\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import de Bokeh pour les cartes\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.io import output_notebook, show, output_file\n",
    "from bokeh.io import export_png\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar, HoverTool, BoxZoomTool, ResetTool, SaveTool\n",
    "from bokeh.palettes import brewer\n",
    "output_notebook()\n",
    "import json\n",
    "\n",
    "#import pour l'API\n",
    "import requests\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://drive.google.com/file/d/1GGOLMc_Ow9yZC9sICegPegDggQuHOD3t/view?usp=drive_link\"\n",
    "url=\"https://drive.google.com/uc?export=download&confirm=1&id=\" + url.split(\"/\")[-2]\n",
    "base = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier avant-goût de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "base.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nécessaire de convertir toutes les colonnes à un format manipulable : dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "\n",
    "    pairs = value.split('||')\n",
    "    result_dict = {}\n",
    "    for pair in pairs:\n",
    "        #Some are corrupted : 1: instead of ::\n",
    "        if '::' in pair:\n",
    "            key, val = pair.split('::', 1)\n",
    "            result_dict[int(key)] = val\n",
    "        else:\n",
    "            key, val = pair.split(':', 1)\n",
    "            result_dict[int(key)] = val\n",
    "    return result_dict\n",
    "\n",
    "updated_base = base.copy()\n",
    "list_of_dict_columns = ['gun_stolen', 'gun_type', 'participant_age', 'participant_age_group', 'participant_gender', 'participant_name', 'participant_relationship', 'participant_status', 'participant_type']\n",
    "updated_base[list_of_dict_columns] = updated_base[list_of_dict_columns].applymap(convert_to_dict)\n",
    "updated_base.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première représentation graphique des incidents de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = gpd.read_file('https://www2.census.gov/geo/tiger/GENZ2020/shp/cb_2020_us_state_20m.zip')\n",
    "\n",
    "incident_counts = updated_base.groupby('state')['incident_id'].count().reset_index()\n",
    "us_states = us_states.merge(incident_counts, left_on='NAME', right_on='state', how='left')\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "us_states.plot(column='incident_id', cmap='Reds', linewidth=0.8, ax=ax, edgecolor='0.8', legend=False)\n",
    "\n",
    "# Add a title and show the plot\n",
    "plt.title('Gun Violence Incidents by State')\n",
    "ax.set_xlim([-140, -60])  # Adjust these values based on your preference\n",
    "ax.set_ylim([20, 50]) \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carte interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_state = [\"AS\", \"AK\", \"HI\", \"GU\", \"VI\", \"MP\", \"PR\"] #to keep the continental USA\n",
    "us_states = us_states[~us_states[\"STUSPS\"].isin(drop_state)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states_geojson = us_states[[\"state\", \"geometry\", \"incident_id\"]].rename(columns= {\"incident_id\" : \"nb_incidents\"})\n",
    "us_states_geojson = GeoJSONDataSource(geojson = us_states_geojson.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapper = LinearColorMapper(palette = brewer['RdBu'][10], low = 400, high = 20000)\n",
    "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8,width = 530, height = 20,\n",
    "                     border_line_color=None,location = (0,0), orientation = 'horizontal')\n",
    "save = SaveTool()\n",
    "hover = HoverTool(tooltips = [ (\"State\",\"@state\"),(\"Nb d'incidents\", \"@nb_incidents\")])\n",
    "p = figure(title=\"Nombre d'incidents par Etats\", tools=[hover, save], width=600, height=350)\n",
    "p.patches(\"xs\",\"ys\",source=us_states_geojson, fill_color = {\"field\" :\"nb_incidents\", \"transform\" : color_mapper})\n",
    "p.add_layout(color_bar, 'above')\n",
    "p.axis.visible = False\n",
    "show(p)\n",
    "#export_png(p, filename=\"plot.png\", width = 600, height = 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fred Api to get data series about the counties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un dictionnaire contenant tous les états et des sous-dictionnaires pour chaque comtés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"180de2e6a1d1e953d270ebf38341cd44\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"category_id\" : \"27281\"}\n",
    "url = \"https://api.stlouisfed.org/fred/category/children?\"\n",
    "response = requests.get(url, params=param)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Process the data as needed\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "liste = data[\"categories\"] #on rentre dans le premier dictionnaire\n",
    "dico_id_states = dict()\n",
    "\n",
    "for dic in liste : #on parcourt la liste en stockant dans un dictionnaire le nom de l'état et le numéro de la catégorie associée\n",
    "    dico_id_states[dic[\"name\"]] = dic[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_relous = [\"Alaska\", \"Louisiana\",\"Virgin Islands\"] #on retire les états qui n'ont pas de comties\n",
    "for state in state_relous :\n",
    "    del dico_id_states[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in dico_id_states.keys() : #on parcourt les états\n",
    "    param[\"category_id\"] = dico_id_states[state] #on ajuste les paramètres de la request pour demander la bonne catégorie\n",
    "    response = requests.get(url, params = param)\n",
    "    data = response.json()\n",
    "    dic = data[\"categories\"][0] #on rentre dans le dictionnaire (toujours le premier)\n",
    "\n",
    "    category_id = dic[\"id\"]\n",
    "    dico_id_states[state] = category_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_states_counties = dict()\n",
    "\n",
    "for state in dico_id_states.keys() : #on parcourt les états\n",
    "    param[\"category_id\"] = dico_id_states[state] #on ajuste les paramètres de la request pour demander la bonne catégorie\n",
    "    response = requests.get(url, params = param)\n",
    "    data = response.json()\n",
    "    liste = data[\"categories\"]\n",
    "\n",
    "    dic_states_counties[state] = dict() #on prépare le dictionnaire\n",
    "    \n",
    "\n",
    "    for dic in liste : #on parcourt les dictionnaires (1 par county)\n",
    "        county_name = dic[\"name\"]\n",
    "        dic_states_counties[state][county_name] = {\"id\" : dic[\"id\"]} #on crée une entrée dans le dic pour le county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_states_counties = dict()\n",
    "\n",
    "# for state in dico_id_states.keys() : #on parcourt les états\n",
    "#     param[\"category_id\"] = dico_id_states[state] #on ajuste les paramètres de la request pour demander la bonne catégorie\n",
    "#     response = requests.get(url, params = param)\n",
    "#     data = response.json()\n",
    "#     liste = data[\"categories\"]\n",
    "\n",
    "#     dic_states_counties[state] = dict() #on prépare le dictionnaire\n",
    "    \n",
    "\n",
    "#     for dic in liste : #on parcourt les dictionnaires (1 par county)\n",
    "#         county_name = dic[\"name\"]\n",
    "#         dic_states_counties[state][county_name] = dict() #on crée une entrée dans le dic pour le county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du taux de chômage moyen entre 2013 et 2017 (inclus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_states_counties[\"Illinois\"][\"DeKalb County, IL\"] = dic_states_counties[\"Illinois\"][\"De Kalb County, IL\"]\n",
    "# del dic_states_counties[\"Illinois\"][\"De Kalb County, IL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#méthode en cherchant la série\n",
    "state = \"Iowa\"\n",
    "\n",
    "dic_state = dic_states_counties[state] #on se place dans le dictionnaire de l'état\n",
    "\n",
    "for county in dic_states_counties[state].keys(): #on parcourt les counties\n",
    "    dic_county = dic_state[county] #on se place dans le dictionnaire du county\n",
    "\n",
    "    url = \"https://api.stlouisfed.org/fred/series/search?\" #on va chercher les séries correspondant au chomage annuel\n",
    "    param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "    param[\"search_text\"] = \"annual+unemployment+rate+\" + county.replace(\",\", \"\").replace(\" \", \"+\") #on écrit les termes de la recherche, prblème avec les filtres\n",
    "    response = requests.get(url, params= param)\n",
    "    data = response.json()\n",
    "    \n",
    "\n",
    "    #print(data)\n",
    "    #print(county)\n",
    "    #print(response.url)\n",
    "\n",
    "    unemployment_rate_serie_id = data[\"seriess\"][0][\"id\"]\n",
    "    dic_county[\"unemployment_rate_id\"] = unemployment_rate_serie_id\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    #récupération de la série en commentaire à cause de la limite de requests par minute\n",
    "    # url = \"https://api.stlouisfed.org/fred/series/observations?\" #on va chercher les séries correspondant au chomage annuel\n",
    "    # param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : unemployment_rate_serie_id, \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2017-01-01\"} \n",
    "    \n",
    "    # response = requests.get(url, params= param)\n",
    "    # data = response.json()\n",
    "    \n",
    "    # print(response.url)\n",
    "\n",
    "    # liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]]\n",
    "    # unemployment_rate_mean = mean(liste_observations)\n",
    "\n",
    "    # dic_county[\"unemployment_rate\"] = unemployment_rate_mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autre méthode : on cherche la série avec \"unemployment rate\" dans le titre et en fréquence mensuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/gun_violence/matis.ipynb Cell 26\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/matis.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m         dic_county[\u001b[39m\"\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m state\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/matis.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m         dic_county[\u001b[39m\"\u001b[39m\u001b[39munemployment_rate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m unemployment_rate_mean\n\u001b[0;32m---> <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/matis.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/matis.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m df_temp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(dic_states_counties[state], orient \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/matis.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m counties_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([counties_df, df_temp])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counties_df = pd.DataFrame()\n",
    "\n",
    "for state in dic_states_counties.keys():\n",
    "    dic_state = dic_states_counties[state] #on se place dans le dictionnaire de l'état\n",
    "\n",
    "    for county in dic_states_counties[state].keys(): #on parcourt les counties\n",
    "        dic_county = dic_state[county] #on se place dans le dictionnaire du county\n",
    "\n",
    "        url = \"https://api.stlouisfed.org/fred/category/series?\"\n",
    "        param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"category_id\" : dic_county[\"id\"]} #on va accéder à la page contenant les séries du county\n",
    "\n",
    "        response = requests.get(url, params= param)\n",
    "        data = response.json()     \n",
    "        \n",
    "        #maintenant on cherche la série dont le titre contient \"unemployment rate\" et dont la fréquence est annuelle\n",
    "        liste_series = data[\"seriess\"]\n",
    "        \n",
    "        for serie in liste_series: #on parcourt les séries,en cherchant celle qui parle du taux de chomage annuel\n",
    "            if (\"Unemployment Rate\" in serie[\"title\"]) and (\"Monthly\" in serie[\"frequency\"]):\n",
    "                dic_county[\"unemployment_rate_id\"] = serie[\"id\"]  #on récupère l'id de la série et on le stock\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    for county in dic_states_counties[state].keys(): #on parcourt les counties\n",
    "        dic_county = dic_state[county] #on se place dans le dictionnaire du county\n",
    "\n",
    "        #récupération de la série\n",
    "        if \"unemployment_rate_id\" in dic_county.keys() :\n",
    "\n",
    "            url = \"https://api.stlouisfed.org/fred/series/observations?\" #on va chercher les séries correspondant au chomage mensuel\n",
    "            param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : dic_county[\"unemployment_rate_id\"], \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2018-03-01\"} \n",
    "        \n",
    "            response = requests.get(url, params= param)\n",
    "            data = response.json()\n",
    "\n",
    "            liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]] #on récupère toutes les observations pour en faire la moyenne sur la période\n",
    "            \n",
    "            unemployment_rate_mean = mean(liste_observations)\n",
    "\n",
    "            dic_county[\"state\"] = state\n",
    "            dic_county[\"unemployment_rate\"] = unemployment_rate_mean\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    df_temp = pd.DataFrame.from_dict(dic_states_counties[state], orient = \"index\")\n",
    "    counties_df = pd.concat([counties_df, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_df.to_csv(path_or_buf=\"counties_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# méthode en cherchant dans la catégorie du county :\n",
    "# state = \"Kansas\"\n",
    "\n",
    "# dic_state = dic_states_counties[state] #on se place dans le dictionnaire de l'état\n",
    "\n",
    "# for county in dic_states_counties[state].keys(): #on parcourt les counties\n",
    "#     dic_county = dic_state[county] #on se place dans le dictionnaire du county\n",
    "\n",
    "#     url = \"https://api.stlouisfed.org/fred/category/series?\"\n",
    "#     param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"category_id\" : dic_county[\"id\"]} #on va accéder à la page contenant les séries du county\n",
    "\n",
    "#     response = requests.get(url, params= param)\n",
    "#     data = response.json()\n",
    "    \n",
    "    \n",
    "\n",
    "#     #maintenant on cherche la série dont le titre contient \"unemployment rate\" et donc la fréquence est annuelle\n",
    "#     liste_series = data[\"seriess\"]\n",
    "    \n",
    "#     for serie in liste_series: #on parcourt les séries,en cherchant celle qui parle du taux de chomage annuel\n",
    "#         if (\"Unemployment Rate\" in serie[\"title\"]) and (\"Annual\" in serie[\"frequency\"]):\n",
    "#             dic_county[\"unemployment_rate_id\"] = serie[\"id\"]  #on récupère l'id de la série et on le stock\n",
    "#     time.sleep(0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_state = dic_states_counties[state] #on se place dans le dictionnaire de l'état\n",
    "\n",
    "# for county in dic_states_counties[state].keys(): #on parcourt les counties\n",
    "#     dic_county = dic_state[county] #on se place dans le dictionnaire du county\n",
    "\n",
    "#     #récupération de la série\n",
    "#     if \"unemployment_rate_id\" in dic_county.keys() :\n",
    "\n",
    "#         url = \"https://api.stlouisfed.org/fred/series/observations?\" #on va chercher les séries correspondant au chomage annuel\n",
    "#         param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : dic_county[\"unemployment_rate_id\"], \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2017-01-01\"} \n",
    "    \n",
    "#         response = requests.get(url, params= param)\n",
    "#         data = response.json()\n",
    "\n",
    "#         liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]] #on récupère toutes les observations pour en faire la moyenne sur la période\n",
    "        \n",
    "#         unemployment_rate_mean = mean(liste_observations)\n",
    "\n",
    "#         dic_county[\"state\"] = state\n",
    "#         dic_county[\"unemployment_rate\"] = unemployment_rate_mean\n",
    "\n",
    "#     time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame.from_dict(dic_states_counties[state], orient = \"index\")\n",
    "# df1[\"state\"] = state\n",
    "# df = pd.concat([df, df1])\n",
    "# df.to_csv(path_or_buf=\"lol2.csv\")\n",
    "# df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problème méthode recherche (en gros pas d'assurance d'avoir le bon comté)\n",
    "Attention : erreur pour le district de Columbia, la vraie série sur  le chomage est LAUCN110010000000003A\n",
    "\n",
    "Pas de hawaii car marche bof\n",
    "\n",
    "Ajustement manuel pour le \"De Kalb County, IL\" en Illinois en remplacant par \"DeKalb County, IL\"\n",
    "\n",
    "Washington County, IN faux : vrai id est : LAUCN181750000000003A et non LAUCN110010000000003A\n",
    "\n",
    "Wayne County, IN faux aussi shit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problème méthode recherche : pas de données pour certains comtés\n",
    "Executin totale : 76 min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
