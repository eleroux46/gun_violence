{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des données avec l'API Fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "#import pour l'API\n",
    "import requests\n",
    "from statistics import mean\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un dictionnaire contenant tous les états et des sous-dictionnaires pour chaque comtés avec l'emploi (et pas la louisiane, sera ajoutée après)\n",
    "\n",
    "76 min d'execution à cause de la limite de requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#définition de l'url et des paramètres de la première requête\n",
    "api_key = \"180de2e6a1d1e953d270ebf38341cd44\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"category_id\" : \"27281\"}\n",
    "url = \"https://api.stlouisfed.org/fred/category/children?\"\n",
    "response = requests.get(url, params=param)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Process the data as needed\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "# création d'un dictionnaire avec les états pour clés et leur catégorie counties pour valeur\n",
    "liste = data[\"categories\"] #on rentre dans le premier dictionnaire\n",
    "dico_id_states = dict()\n",
    "\n",
    "for dic in liste : #on parcourt la liste en stockant dans un dictionnaire le nom de l'état et le numéro de la catégorie associée\n",
    "    dico_id_states[dic[\"name\"]] = dic[\"id\"]\n",
    "\n",
    "state_relous = [\"Alaska\", \"Louisiana\",\"Virgin Islands\"] #on retire les états qui n'ont pas de comties\n",
    "for state in state_relous :\n",
    "    del dico_id_states[state]\n",
    "\n",
    "for state in dico_id_states.keys() : #on parcourt les états\n",
    "    param[\"category_id\"] = dico_id_states[state] #on ajuste les paramètres de la request pour demander la bonne catégorie\n",
    "    response = requests.get(url, params = param)\n",
    "    data = response.json()\n",
    "    dic = data[\"categories\"][0] #on rentre dans le dictionnaire (toujours le premier, c'est celui qui contient les comtés)\n",
    "\n",
    "    category_id = dic[\"id\"] #on suavegarde la catégorie contenant les comtés de l'état\n",
    "    dico_id_states[state] = category_id\n",
    "    time.sleep(0.5)\n",
    "\n",
    "dic_states_counties = dict() #on initialise un nouveau dictionnaire, qui sera de la forme : {etat1 : {comté1 : {}, comté2 :}, état2 : ....}\n",
    "\n",
    "for state in dico_id_states.keys() : #on parcourt les états\n",
    "    param[\"category_id\"] = dico_id_states[state] #on ajuste les paramètres de la request pour demander la bonne catégorie\n",
    "    response = requests.get(url, params = param)\n",
    "    data = response.json()\n",
    "    liste = data[\"categories\"] #on obtient la liste des comtés de l'état\n",
    "\n",
    "    dic_states_counties[state] = dict() #on prépare le dictionnaire qui contiendra aura les comtés de l'état pour clés\n",
    "    \n",
    "\n",
    "    for dic in liste : #on parcourt les dictionnaires (1 par county)\n",
    "        county_name = dic[\"name\"] #on récupère le nom du county\n",
    "        dic_states_counties[state][county_name] = {\"id\" : dic[\"id\"]} #on crée une entrée dans le dic pour le county et on sauvegarde sa catégorie\n",
    "\n",
    "counties_df = pd.DataFrame() #on  créé le dataframe qui servira à tout sauvegarder et à convertir en csv\n",
    "\n",
    "\n",
    "for state in dic_states_counties.keys(): #on va parcourir état par état (car c'est les premières clés)\n",
    "    dic_state = dic_states_counties[state] #on se place dans le dictionnaire de l'état\n",
    "\n",
    "    for county in dic_states_counties[state].keys(): #on parcourt les counties\n",
    "        dic_county = dic_state[county] #on se place dans le dictionnaire du county\n",
    "\n",
    "        url = \"https://api.stlouisfed.org/fred/category/series?\"\n",
    "        param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"category_id\" : dic_county[\"id\"]} #on va accéder à la page contenant les séries du county\n",
    "\n",
    "        response = requests.get(url, params= param)\n",
    "        data = response.json()     \n",
    "\n",
    "        #maintenant on cherche la série dont le titre contient \"unemployment rate\" et dont la fréquence est annuelle\n",
    "        liste_series = data[\"seriess\"]\n",
    "        \n",
    "        for serie in liste_series: #on parcourt les séries,en cherchant celle qui parle du taux de chomage annuel\n",
    "            if (\"Unemployment Rate\" in serie[\"title\"]) and (\"Monthly\" in serie[\"frequency\"]):\n",
    "                dic_county[\"unemployment_rate_id\"] = serie[\"id\"]  #on récupère l'id de la série et on le stock\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    for county in dic_states_counties[state].keys(): #on parcourt les counties\n",
    "        dic_county = dic_state[county] #on se place dans le dictionnaire du county\n",
    "\n",
    "        #récupération de la série\n",
    "        if \"unemployment_rate_id\" in dic_county.keys() :\n",
    "\n",
    "            url = \"https://api.stlouisfed.org/fred/series/observations?\" #on va chercher les séries correspondant au chomage mensuel\n",
    "            param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : dic_county[\"unemployment_rate_id\"], \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2018-03-01\"} \n",
    "        \n",
    "            response = requests.get(url, params= param)\n",
    "            data = response.json()\n",
    "\n",
    "            liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]] #on récupère toutes les observations pour en faire la moyenne sur la période\n",
    "            \n",
    "            unemployment_rate_mean = mean(liste_observations)\n",
    "\n",
    "            dic_county[\"state\"] = state\n",
    "            dic_county[\"unemployment_rate\"] = unemployment_rate_mean\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    df_temp = pd.DataFrame.from_dict(dic_states_counties[state], orient = \"index\")\n",
    "    counties_df = pd.concat([counties_df, df_temp])\n",
    "\n",
    "counties_df.to_csv(path_or_buf=\"counties_data2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le code précédent, on obtient un csv contenant les comtés en index, une colonne pour l'id de la catégorie du comté, une colonne pour l'id de la série sur le taux de chômage, une sur le taux moyen de chômage entre janvier 2013 et mars 2018 et enfin une avec l'état dans lequel est situé le comté. Il n'y a pas les parish de Louisiane. Il n'y pas l'Alaska ni les îles vierges.\n",
    "\n",
    "Ce fichier csv est enregistré et servira de base de travail plus tard, plutôt que rééxécuter le code (qui prend plus d'1h à tourner à cause des limites de requests par minutes).\n",
    "\n",
    "On va maintenant ajouter les parish de louisiane (on aurait pu les ajouter dès le départ, mais pas grave)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère le csv précédent\n",
    "url=\"https://drive.google.com/file/d/1zKdZxFTbrolYaEK9EzadOUmT4N9XWXSt/view?usp=drive_link\"\n",
    "url=\"https://drive.google.com/uc?export=download&confirm=1&id=\" + url.split(\"/\")[-2]\n",
    "county_data_no_louisiana_df = pd.read_csv(url)\n",
    "county_data_no_louisiana_df.rename(columns={\"Unnamed: 0\" : \"county_name\", \"id\" : \"category_id\"}, inplace=True)\n",
    "county_data_no_louisiana_df.set_index(\"county_name\", inplace=True)\n",
    "\n",
    "county_data_df = county_data_no_louisiana_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_louisiana = dict() #création du dictionnaire \n",
    "\n",
    "# on va se placer dans la catégorie de la louisiane\n",
    "api_key = \"180de2e6a1d1e953d270ebf38341cd44\"\n",
    "url = \"https://api.stlouisfed.org/fred/category/children?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"category_id\" : \"28461\"} #28461 est la catégorie des parish de la louisiane\n",
    "\n",
    "response = requests.get(url, params=param)\n",
    "data = response.json()\n",
    "liste_parish = data[\"categories\"] #on rentre dans la liste des dicionnaires de la forme {'id': 28462, 'name': 'Acadia Parish, LA', 'parent_id': 28461}, 1 par parish\n",
    "\n",
    "for parish_dic in liste_parish: #on parcourt les dictionnaires 1 par 1\n",
    "    dic_louisiana[parish_dic[\"name\"]] = {\"category_id\" : parish_dic[\"id\"], \"state\" : \"Louisiana\"} #on créé dans notre dictionnaire une entrée au nom du parish et avec les données qui nous intéressent\n",
    "\n",
    "# Récupération de l'id de la série du taux de chomage pour chaque parish\n",
    "url = \"https://api.stlouisfed.org/fred/category/series?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "\n",
    "for parish in dic_louisiana.keys(): #on parcourt les parish\n",
    "    parish_dic = dic_louisiana[parish] # pour accéder facilement au dictionnaire du parish\n",
    "\n",
    "    param[\"category_id\"] = parish_dic[\"category_id\"]\n",
    "    response = requests.get(url, params = param)    \n",
    "    data = response.json()     \n",
    "\n",
    "    #maintenant on cherche la série dont le titre contient \"unemployment rate\" et dont la fréquence est annuelle\n",
    "    liste_series = data[\"seriess\"]\n",
    "        \n",
    "    for serie in liste_series: #on parcourt les séries,en cherchant celle qui parle du taux de chomage annuel\n",
    "        if (\"Unemployment Rate\" in serie[\"title\"]) and (\"Monthly\" in serie[\"frequency\"]):\n",
    "            parish_dic[\"unemployment_rate_id\"] = serie[\"id\"]  #on récupère l'id de la série et on le stock\n",
    "    time.sleep(0.5) #pause pour pas dépasser le nombre de requêtes par min\n",
    "\n",
    "\n",
    "\n",
    "# Récupération du taux de chomage moyen entre janvier 2013 et mars 2018 inclus\n",
    "url = \"https://api.stlouisfed.org/fred/series/observations?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "\n",
    "for parish in dic_louisiana.keys(): #on parcourt les parish\n",
    "    parish_dic = dic_louisiana[parish] # pour accéder facilement au dictionnaire du parish\n",
    "\n",
    "    if \"unemployment_rate_id\" in parish_dic.keys() :\n",
    "\n",
    "            param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : parish_dic[\"unemployment_rate_id\"], \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2018-03-01\"} \n",
    "        \n",
    "            response = requests.get(url, params= param)\n",
    "            data = response.json()\n",
    "\n",
    "            liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]] #on récupère toutes les observations pour en faire la moyenne sur la période\n",
    "            \n",
    "            unemployment_rate_mean = mean(liste_observations)\n",
    "            parish_dic[\"unemployment_rate\"] = unemployment_rate_mean\n",
    "\n",
    "    county_data_df.loc[parish] = parish_dic #on ajoute le parish au dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data_df.to_csv(\"county_data_complete.csv\") #on sauvegarde les donnéees complètes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère le csv précédemment enregistré (contient unemployement):\n",
    "url=\"https://drive.google.com/file/d/1RWRfunmX_Vu_XLoxbEzmCrB27FPc0wbO/view?usp=drive_link\"\n",
    "url=\"https://drive.google.com/uc?export=download&confirm=1&id=\" + url.split(\"/\")[-2]\n",
    "county_data_df = pd.read_csv(url)\n",
    "county_data_df.set_index(\"county_name\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération de la population par county / parish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/gun_violence/recup_data_fred_api.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/recup_data_fred_api.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m data\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/recup_data_fred_api.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m liste_observations \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39m(obs[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m data[\u001b[39m\"\u001b[39m\u001b[39mobservations\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m#on récupère toutes les observations pour en faire la moyenne sur la période\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/recup_data_fred_api.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m resident_population_mean \u001b[39m=\u001b[39m mean(liste_observations)\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/recup_data_fred_api.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m county_data_df\u001b[39m.\u001b[39mloc[county, \u001b[39m\"\u001b[39m\u001b[39mresident_population\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m resident_population_mean\n\u001b[1;32m     <a href='vscode-notebook-cell://user-mbruneau-705754-0.user.lab.sspcloud.fr/home/onyxia/work/gun_violence/recup_data_fred_api.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/statistics.py:328\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    326\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[39mraise\u001b[39;00m StatisticsError(\u001b[39m'\u001b[39m\u001b[39mmean requires at least one data point\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    329\u001b[0m T, total, count \u001b[39m=\u001b[39m _sum(data)\n\u001b[1;32m    330\u001b[0m \u001b[39massert\u001b[39;00m count \u001b[39m==\u001b[39m n\n",
      "\u001b[0;31mStatisticsError\u001b[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "# Récupération de l'id de la série Resident Population pour chaque county\n",
    "api_key = \"180de2e6a1d1e953d270ebf38341cd44\"\n",
    "url = \"https://api.stlouisfed.org/fred/category/series?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "\n",
    "for county, row in county_data_df.iterrows(): #on itère sur chaque county\n",
    "    param[\"category_id\"] = row[\"category_id\"]\n",
    "    response = requests.get(url, params=param)\n",
    "    data = response.json()     \n",
    "\n",
    "    #maintenant on cherche la série dont le titre contient \"unemployment rate\" et dont la fréquence est annuelle\n",
    "    liste_series = data[\"seriess\"]\n",
    "        \n",
    "    for serie in liste_series: #on parcourt les séries,en cherchant celle qui parle du taux de chomage annuel\n",
    "        if (\"Resident Population\" in serie[\"title\"]) and (\"Annual\" in serie[\"frequency\"]):\n",
    "            county_data_df.loc[county, \"resident_population_id\"] = serie[\"id\"]  #on récupère l'id de la série et on le stock\n",
    "    time.sleep(0.5) #pause pour pas dépasser le nombre de requêtes par min\n",
    "\n",
    "\n",
    "#Récupération des données de la série\n",
    "url = \"https://api.stlouisfed.org/fred/series/observations?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "\n",
    "for county, row in county_data_df.iterrows():\n",
    "    if row[\"resident_population_id\"] != \"nan\":\n",
    "\n",
    "        param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : row[\"resident_population_id\"], \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2017-01-01\"}\n",
    "        response = requests.get(url, params=param)\n",
    "        data=response.json()\n",
    "\n",
    "        liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]] #on récupère toutes les observations pour en faire la moyenne sur la période\n",
    "        \n",
    "        if len(liste_observations) > 0 : #pas présent à l'origine, ce qui a causé un problème\n",
    "            resident_population_mean = mean(liste_observations)\n",
    "            county_data_df.loc[county, \"resident_population\"] = resident_population_mean\n",
    "        \n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problème à partir de \"Clifton Forge City, VA\" car la série est arrêtée, la moyenne ne peut donc pas se faire...\n",
    "\n",
    "De plus les villes de viriginia n'ont pas de colonne état --> devait être ailleurs, pas grave car leur comté est quand même dedans\n",
    "\n",
    "On va repartir de là où ca s'est arrêté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.stlouisfed.org/fred/series/observations?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "\n",
    "for county, row in county_data_df.loc[\"Clifton Forge City, VA\":,].iterrows():\n",
    "    if row[\"resident_population_id\"] != \"nan\":\n",
    "\n",
    "        param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : row[\"resident_population_id\"], \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2017-01-01\"}\n",
    "        response = requests.get(url, params=param)\n",
    "        data=response.json()\n",
    "\n",
    "        liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]] #on récupère toutes les observations pour en faire la moyenne sur la période\n",
    "        \n",
    "        if len(liste_observations) > 0 :\n",
    "            resident_population_mean = mean(liste_observations)\n",
    "            county_data_df.loc[county, \"resident_population\"] = resident_population_mean\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data_df.to_csv(\"resident_population.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3114"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_data_df.notna().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du median household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère le csv précédemment enregistré (contient unemployement):\n",
    "url=\"https://drive.google.com/file/d/1neZeKIIxpm0NJ3UKvH_H-bQBLBKbDv8t/view?usp=drive_link\"\n",
    "url=\"https://drive.google.com/uc?export=download&confirm=1&id=\" + url.split(\"/\")[-2]\n",
    "county_data_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de l'id de la série Resident Population pour chaque county\n",
    "api_key = \"180de2e6a1d1e953d270ebf38341cd44\"\n",
    "url = \"https://api.stlouisfed.org/fred/category/series?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "\n",
    "for county, row in county_data_df.iterrows(): #on itère sur chaque county\n",
    "    param[\"category_id\"] = row[\"category_id\"]\n",
    "    response = requests.get(url, params=param)\n",
    "    data = response.json()     \n",
    "\n",
    "    #maintenant on cherche la série dont le titre contient \"unemployment rate\" et dont la fréquence est annuelle\n",
    "    liste_series = data[\"seriess\"]\n",
    "        \n",
    "    for serie in liste_series: #on parcourt les séries,en cherchant celle qui parle du taux de chomage annuel\n",
    "        if (\"Estimate of Median Household Income\" in serie[\"title\"]) and (\"Interval\" not in serie[\"title\"]):\n",
    "            county_data_df.loc[county, \"median_household_income_id\"] = serie[\"id\"]  #on récupère l'id de la série et on le stock\n",
    "    time.sleep(0.5) #pause pour pas dépasser le nombre de requêtes par min\n",
    "\n",
    "\n",
    "#Récupération des données de la série\n",
    "url = \"https://api.stlouisfed.org/fred/series/observations?\"\n",
    "param = {\"api_key\" : api_key, \"file_type\" : \"json\"}\n",
    "\n",
    "for county, row in county_data_df.iterrows():\n",
    "    if row[\"median_household_income_id\"] != \"nan\":\n",
    "\n",
    "        param = {\"api_key\" : api_key, \"file_type\" : \"json\", \"series_id\" : row[\"median_household_income_id\"], \"observation_start\" : \"2013-01-01\", \"observation_end\" : \"2017-01-01\"}\n",
    "        response = requests.get(url, params=param)\n",
    "        data=response.json()\n",
    "\n",
    "        liste_observations = [float(obs[\"value\"]) for obs in data[\"observations\"]] #on récupère toutes les observations pour en faire la moyenne sur la période\n",
    "        \n",
    "        if len(liste_observations) > 0 :\n",
    "            median_household_income_mean = mean(liste_observations)\n",
    "            county_data_df.loc[county, \"median_household_income\"] = median_household_income_mean\n",
    "        \n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data_df.to_csv(\"median_household_income.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
